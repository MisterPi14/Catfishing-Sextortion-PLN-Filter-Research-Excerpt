# Catfishing-Sextortion PLN Filter: Research Excerpt

## Descripci√≥n General

Este repositorio contiene un **fragmento de una investigaci√≥n en desarrollo** sobre detecci√≥n y clasificaci√≥n de fraudes cibern√©ticos mediante t√©cnicas de Procesamiento de Lenguaje Natural (PLN). El objetivo principal es identificar y clasificar mensajes de estafas en comunicaciones digitales.

### Categor√≠as de Clasificaci√≥n

El sistema clasifica mensajes de texto en tres categor√≠as:

1. **Catfishing** - Creaci√≥n de identidades falsas para enga√±ar emocionalmente a v√≠ctimas, solicitando dinero, informaci√≥n personal o generando dependencia emocional
2. **Sextortion** - Chantaje sexual donde el atacante amenaza con publicar contenido √≠ntimo a menos que se cumplan demandas (generalmente monetarias)
3. **Harmless** - Comunicaciones leg√≠timas sin intenci√≥n fraudulenta

---

## Prop√≥sito de la Investigaci√≥n

Evaluar y comparar el desempe√±o de modelos de lenguaje (LLMs) locales en la identificaci√≥n de patrones de fraude cibern√©tico, utilizando dos enfoques fundamentales en PLN:

- **Zero-Shot Learning**: Clasificaci√≥n sin ejemplos previos, bas√°ndose √∫nicamente en definiciones de categor√≠as
- **Few-Shot Learning**: Clasificaci√≥n con ejemplos sint√©ticos para mejorar la comprensi√≥n contextual

---

## Estructura del Repositorio

```
‚îú‚îÄ‚îÄ ModelsClassificationTests.ipynb    # Notebook principal de evaluaci√≥n de modelos
‚îú‚îÄ‚îÄ CSV-Generator.py                   # Script para consolidar resultados en reportes CSV
‚îú‚îÄ‚îÄ scam-examples/
‚îÇ   ‚îî‚îÄ‚îÄ sintetic/                      # Ejemplos sint√©ticos (formato JSON)
‚îî‚îÄ‚îÄ LMMs-Classification-Test-Results/  # Directorio de salida de evaluaciones (generado en ejecuci√≥n)
    ‚îî‚îÄ‚îÄ Few-Shot-Sintetic-Aproach/     # Resultados de evaluaciones
```

---

## üîß Requisitos de Ejecuci√≥n

### Dependencias Principales

El proyecto requiere las siguientes herramientas y librer√≠as:

#### 1. **Entorno Python**
- Python 3.7 o superior

#### 2. **Librer√≠as Requeridas**

##### Cliente Ollama: `ollama-python`
```bash
pip install ollama
```
- **Nombre t√©cnico**: `ollama`
- **Prop√≥sito**: Proporciona el cliente Python para interactuar con modelos de lenguaje locales ejecut√°ndose en Ollama
- **Funci√≥n en el proyecto**: Conecta con la instancia local de Ollama (por defecto en `http://localhost:11434`) para enviar prompts y obtener predicciones de los modelos

##### M√©tricas de Clasificaci√≥n: `scikit-learn`
```bash
pip install scikit-learn
```
- **Nombre t√©cnico**: `sklearn` (nombre de importaci√≥n) / `scikit-learn` (nombre del paquete)
- **M√≥dulos espec√≠ficos utilizados**:
  - `sklearn.metrics.classification_report`: Genera reportes detallados con m√©tricas por clase (precision, recall, f1-score, support)
  - `sklearn.metrics.accuracy_score`: Calcula la precisi√≥n general del modelo
- **Prop√≥sito en el proyecto**: Evaluar el desempe√±o de cada modelo mediante m√©tricas est√°ndar de clasificaci√≥n

##### Librer√≠as Est√°ndar (incluidas en Python):
- `json`: Lectura/escritura de archivos JSON con configuraciones y resultados
- `csv`: Generaci√≥n de reportes CSV
- `os` y `pathlib`: Manejo de directorios y rutas
- `time` y `statistics`: Medici√≥n de tiempos de evaluaci√≥n
- `subprocess`: Interacci√≥n con comandos del sistema (ej: `ollama list`)
- `re` (regex): Procesamiento y filtrado de respuestas de modelos
- `datetime`: Timestamps de evaluaciones

#### 3. **Herramienta Requerida: Ollama**

**Ollama** es un framework que permite ejecutar modelos de lenguaje de c√≥digo abierto de forma local:

- **Descarga**: https://ollama.ai/
- **Requisito de ejecuci√≥n**: Debe estar instalado y ejecut√°ndose antes de correr el notebook
- **Verificaci√≥n de instalaci√≥n**:
  ```bash
  ollama --version
  ```
- **Verificaci√≥n de disponibilidad**:
  ```bash
  ollama list  # Muestra los modelos disponibles
  ```
- **Puerto por defecto**: `http://localhost:11434` (configurable en el notebook)

---

## Dataset de Prueba

El proyecto utiliza **dataset sint√©tico** generado espec√≠ficamente para esta investigaci√≥n. Los datos sint√©ticos est√°n organizados en archivos JSON dentro del directorio `scam-examples/sintetic/`.

### Caracter√≠sticas del Dataset Sint√©tico

- **Formato**: Archivos JSON estructurados con ejemplos de mensajes por categor√≠a
- **Estructura esperada**: 
  ```json
  {
    "examples": [
      {
        "text": "mensaje de prueba aqu√≠",
        "category": "catfishing|sextortion|harmless"
      }
    ]
  }
  ```
- **Prop√≥sito**: Permitir pruebas reproducibles y evaluaciones consistentes sin dependencia de datos reales

---

## Instalaci√≥n y Configuraci√≥n

### Paso 1: Clonar el Repositorio
```bash
git clone https://github.com/MisterPi14/Catfishing-Sextortion-PLN-Filter-Research-Excerpt.git
cd Catfishing-Sextortion-PLN-Filter-Research-Excerpt
```

### Paso 2: Crear Entorno Virtual (Recomendado)
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### Paso 3: Instalar Dependencias
```bash
pip install ollama scikit-learn
```

### Paso 4: Verificar Ollama
```bash
ollama list  # Verificar modelos disponibles
```

### Paso 5: Ejecutar el Notebook

Abrir `ModelsClassificationTests.ipynb` en Jupyter Notebook o JupyterLab:
```bash
jupyter notebook ModelsClassificationTests.ipynb
```

O en Jupyter Lab:
```bash
jupyter lab ModelsClassificationTests.ipynb
```

---

## üìñ Uso

### Workflow Principal

#### 1. **ModelsClassificationTests.ipynb**

Notebook que ejecuta la evaluaci√≥n completa de modelos:

- **Configuraci√≥n inicial**: Define par√°metros de ejecuci√≥n (enfoques, directorio de ejemplos, modelos a evaluar)
- **Carga de ejemplos**: Lee archivos JSON sint√©ticos de `scam-examples/sintetic/`
- **Inicializaci√≥n de cliente Ollama**: Establece conexi√≥n con la instancia local
- **Evaluaci√≥n iterativa**: Para cada modelo, realiza predicciones sobre el dataset de prueba
- **Generaci√≥n de reportes**: Exporta resultados en formato JSON con:
  - Metadatos: Nombre del modelo, tama√±o, fecha, versi√≥n del prompt
  - Predicciones: Respuestas raw del modelo
  - M√©tricas: Accuracy, precision, recall, f1-score por clase
  - Tiempos: Duraci√≥n total y por predicci√≥n

**Salida**: Archivos JSON en `LMMs-Classification-Test-Results/Few-Shot-Sintetic-Aproach/`

#### 2. **CSV-Generator.py**

Script de post-procesamiento que consolida resultados:

```bash
python CSV-Generator.py
```

**Funciones**:
- Lee todos los archivos JSON generados por el notebook
- Extrae y redondea m√©tricas (4 decimales)
- Convierte formato num√©rico a est√°ndar europeo (coma decimal)
- Genera CSV con separador `;` (semicolon-delimited)
- Organiza columnas: Modelo ‚Üí Accuracy ‚Üí M√©tricas por clase ‚Üí M√©tricas agregadas

**Salida**: Archivo CSV en `LMMs-Classification-Test-Results/` con nombre seg√∫n la carpeta evaluada

---

## Configuraci√≥n Personalizada

Dentro de `ModelsClassificationTests.ipynb`, editar variables de configuraci√≥n:

```python
# Directorio de salida de resultados
OUTPUT_DIR = 'LMMs-Classification-Test-Results/Few-Shot-Sintetic-Aproach'

# Versi√≥n del prompt utilizado
PROMPT_VERSION = 'v1.3'

# Activar/Desactivar caracter√≠sticas
DEFINITIONS = False      # Incluir definiciones en el prompt
DICTIONARY = False       # Incluir diccionario de regionalismos
EXAMPLES = True          # Incluir ejemplos sint√©ticos (Few-Shot)

# Directorio con ejemplos y diccionarios JSON
EXAMPLES_DIR = 'scam-examples/sintetic'

# Selecci√≥n de modelos espec√≠ficos
SELECTED_MODELS_ONLY = True
MODELS_SELECTION = ["nombre-del-modelo:tama√±o"]
```

---

## Salidas y Resultados

### Formato JSON de Evaluaci√≥n

```json
{
  "metadata": {
    "model_name": "nombre-modelo",
    "model_size": "tama√±o",
    "evaluation_date": "ISO-8601-format",
    "prompt_version": "v1.3",
    "training_dataset_size": "X samples (desglose por categor√≠a)",
    "examples_directory": "ruta/de/ejemplos",
    "test_dataset_size": "X samples (10 de cada categor√≠a)"
  },
  "results": {
    "classification_report": {
      "accuracy": 0.8333,
      "catfishing": {
        "precision": 0.8,
        "recall": 0.8,
        "f1-score": 0.8,
        "support": 10
      },
      "sextortion": {
        "precision": 0.9,
        "recall": 0.9,
        "f1-score": 0.9,
        "support": 10
      },
      "harmless": {
        "precision": 0.8,
        "recall": 0.8,
        "f1-score": 0.8,
        "support": 10
      }
    },
    "timing_metrics": {
      "total_evaluation_time_seconds": 125.34,
      "average_time_per_prediction_seconds": 4.18,
      "samples_per_second": 0.24
    }
  }
}
```

### Formato CSV Consolidado

| Model | accuracy | catfishing_precision | catfishing_recall | ... | weighted avg_f1-score |
|-------|----------|----------------------|-------------------|-----|----------------------|
| modelo_v1 (size) | 0,8333 | 0,8 | 0,8 | ... | 0,8333 |
| modelo_v2 (size) | 0,9167 | 0,9 | 0,9 | ... | 0,9167 |

---

## Enfoque Metodol√≥gico

### Zero-Shot Learning
Clasifica mensajes bas√°ndose √∫nicamente en definiciones de categor√≠as sin ejemplos previos. √ötil para evaluar la capacidad de generalizaci√≥n del modelo.

### Few-Shot Learning
Proporciona ejemplos sint√©ticos de cada categor√≠a en el prompt para mejorar la comprensi√≥n contextual. Demuestra c√≥mo ejemplos representativos mejoran la precisi√≥n de clasificaci√≥n.

---

## Notas sobre el Dataset Sint√©tico

- **Generaci√≥n**: Los ejemplos fueron creados mediante t√©cnicas de s√≠ntesis de datos
- **Prop√≥sito**: Garantizar reproducibilidad y consistencia en las evaluaciones
- **Ventaja**: Permite pruebas sin depender de datos reales sensibles
- **Limitaci√≥n**: Puede no capturar toda la complejidad del mundo real

---

## Limitaciones y Consideraciones

- Este es un **fragmento de una investigaci√≥n en desarrollo**, no la soluci√≥n final
- Los resultados son espec√≠ficos al enfoque Few-Shot con ejemplos sint√©ticos
- El rendimiento puede variar seg√∫n el modelo LLM seleccionado
- Requiere Ollama ejecut√°ndose localmente con modelos instalados
- El dataset de prueba es limitado (10 muestras por categor√≠a)

---

## Trabajo Futuro

- Evaluaci√≥n con datasets m√°s grandes y diversificados
- Comparaci√≥n entre Zero-Shot y Few-Shot de forma cuantitativa
- Integraci√≥n de datos reales (respetando privacidad)
- Fine-tuning de modelos espec√≠ficamente para esta tarea
- Optimizaci√≥n del tama√±o y estructura de prompts
- An√°lisis de errores y casos edge

---

## Licencia

Especificar seg√∫n corresponda a tu proyecto

---

## Contacto

**Autor**: MisterPi14  
**Proyecto**: Catfishing-Sextortion PLN Filter Research  
**Estado**: Investigaci√≥n en desarrollo

---

### Referencias T√©cnicas

- **Ollama**: https://ollama.ai/
- **Scikit-learn Classification Report**: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report
- **Zero-Shot Learning**: Brown et al. (2020) - Language Models are Few-Shot Learners
- **Few-Shot Learning**: Contexto din√°mico mediante ejemplos sint√©ticos
